ANSWERS:-
1)
page = requests.get("https://www.imdb.com/list/ls056092300/",verify=False)
soup = BeautifulSoup(page.content)
Names = []
for i in soup.find_all(class_="lister-item-header"):
    Names.append(i.text.replace("\n"," "))
Names   
Rating = []
for i in soup.find_all("div",class_="ipl-rating-widget"):
    Rating.append(i.text.replace("\n"," "))
Rating
Year_of_release = []
for i in soup.find_all("span",class_="lister-item-year text-muted unbold"):
    Year_of_release.append(i.text)
Year_of_release
import pandas as pd
df = pd.DataFrame({"Names":Names,"Rating":Rating,"Year_of_release":Year_of_release})
df

2)
page = requests.get("https://peachmode.com/pages/search?q=bags",verify=False)
page
soup = BeautifulSoup(page.content)
soup
product_name = []
for i in soup.find_all("div",class_="product-title"):
    product_name.append(i.text)
product_name
price = []
for i in soup.find_all("span",class_="price st-money money done"):
    price.append(i.text)
price
discount = []
for i in soup.find_all("span",class_="discounted_price st-money money done"):
    discont.append(i.text)
discount

3)
(a)
page = requests.get("https://www.icc-cricket.com/",verify=False)
soup = BeautifulSoup(page.content,"html.parser")
name = []
for i in soup.find_all(class_="si-team-name"):
    name.append(i.text)
name
matches = []
for i in soup.find_all("div",class_="si-table-data si-matches"):
    matches.append(i.text)
matches
points = []
for i in soup.find_all("div",class_="si-table-data si-pts"):
    points.append(i.text)
points
rating = []
for i in soup.find_all("div",class_="si-table-data si-rating"):
    rating.append(i.text)
rating
(b)
Team = []
for i in soup.find_all("span",class_="si-sname si-text"):
    Team.append(i.text)
Team
Rating = []
for i in soup.find_all("div",class_="si-table-data si-rating"):
    Rating.append(i.text)
Rating
(c)
Team = []
for i in soup.find_all("span",class_="si-team-name"):
    Team.append(i.text)
Rating = []
for i in soup.find_all("div",class_="si-table-data si-rating"):
    Rating.append(i.text)

4)
page = requests.get("https://www.patreon.com/coreyms",verify=False)
page
soup = BeautifulSoup(page.content)
soup
Heading = []
for i in soup.find_all("div",class_="sc-1cvoi1y-0 hxhWXn"):
    Heading.append(i.text)
Heading
date = []
for i in soup.find_all(class_="sc-fKVqWL cHPUtA"):
    date.append(i.text)
date
content= []
for i in soup.find_all("div",class_="sc-cfnzm4-0 kJujbw"):
    content.append(i.text)
content
likes = []
for i in soup.find_all("div",class_="sc-dkPtRN kBeyDw"):
    likes.append(i.text)
likes

5)
page = requests.get("https://www.nobroker.in/",verify=False)
page
soup = BeautifulSoup(page.content)
soup
title = []
for i in soup.find_all("a",href="/property/buy/3-bhk-apartment-for-sale-in-basavanagudi-bangalore/ff8081816ce8bdac016ced009da8355c/detail"):
    title.append(i.text)
title
loc = []
for i in soup.find_all("span",class_="mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0.1p po:max-w-95"):
    loc.append(i.text)
loc
emi = soup.find("span",class_="font-semi-bold heading-6",id_="roomType")
emi.text
price = soup.find("span",class_="font-semi-bold heading-6")
print(price)
area = soup.find(class_="flex",id_="unitCode")
print(area)

6)
page = requests.get("https://www.bewakoof.com/bestseller?sort=popular%20.",verify=False)
page
soup = BeautifulSoup(page.content)
soup
product_name = []
for i in soup.find_all("div",class_="productNaming bkf-ellipsis"):
    product_name.append(i.text)
product_name
price = []
for i in soup.find_all("div",class_="discountedPriceText clr-p-black false"):
    price.append(i.text)
price
img = []
for i in soup.find_all("img src"=="https://images.bewakoof.com/t640/women-aop-oversize-t-shirt-4-580364-1683887449-1.jpg"):
    img.append(i.text.replace("\n"," "))
img

7)
page = requests.get("https://www.cnbc.com/world/?region=world",verify=False)
page
soup = BeautifulSoup(page.content)
soup
heading= []
for i in soup.find_all("div",class_="RiverHeadline-headline RiverHeadline-hasThumbnail"):
    heading.append(i.text)
heading
date = []
for i in soup.find_all("span",class_="RiverByline-datePublished"):
    date.append(i.text)
date
print("The href links are :")
for link in soup.find_all('a'):
   print(link.get('href'))

8)
page = requests.get("https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/",verify=False)
page
soup = BeautifulSoup(page.content)
soup
paper_title = []
for i in soup.find_all(class_="h5 article-title"):
    paper_title.append(i.text.replace("\n",""))
paper_title
date = []
for i in soup.find_all(class_="article-date"):
    date.append(i.text)
date
author = []
for i in soup.find_all(class_="article-authors"):
    author.append(i.text)
author
